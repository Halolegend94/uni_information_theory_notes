
\chapter{Error correcting codes}
Error correcting codes (ECC) arise in probabilistic contexts. Consider a memory device with $n$ cells. We can model the content as a string $\str{x} \in \{0, 1\}^n$. The device decays; each cell can flip its value independently from the others with a certain probability (uniform). The probability $p$ is usually $< 1/2$. We can expect no more than $np$ flips. Can we guarantee recovery from so many errors? Yes, thanks to algebra. The string $\str{x}$ can be converted into anything inside a ball of radious $np$. We want that two strings $\str{x}$ and $\str{y}$ are distant, so that their balls do not intersect. The pairwise distance of the words should be $\geq 2np + 1$.

Let $\mathcal{C} \subseteq \{0, 1\}^n$ be a block code. This should have some properties, for example $|C|$ should be large. Define
\[
 d(\mathcal{C}) = \min_{\{\str{x}, \str{y}\}\in \binom{\mathcal{C}}{2}}d_H(\str{x}, \str{y}),
\]
where 
\[
\binom{\mathcal{C}}{2} = \{\{\str{x}, \str{y}\}\ |\ \str{x}, \str{y} \in \mathcal{C} \wedge \str{x} \not= \str{y}\}. 
\]

So $d$ tells how close the closest elements are. $d(\mathcal{C})$ should be large too. What is the best possible tradeoff?

\[
 M(n, d) = \max_{C | d(\mathcal{C}) \geq d}|\mathcal{C}|
\]

This says that we are concentrating on codes for which $d(\mathcal{C}) \geq d$. We can think of the graph for which $V = \{0, 1\}^n$ and $X, Y \in \binom{V}{2}$ have an edge iff $d_H(\str{x}, \str{y}) \geq d$. We are looking for the largest clique. We try to make this simpler by looking at the problem from an asymptotic point of view. $M(n, n\delta)$ grows to infinity exponentially in $n$.

\[
 \dfrac{1}{n}\log(M(n, n\delta))
\]
does not (grow exponentially ?). We look at the superior limit
 
\[
 R(\delta) = \overline{\lim_{n \rightarrow \infty}}  \dfrac{1}{n}\log(M(n, n\delta)),
\]

where $R$ denotes the rate. $M(n, n\delta)$ is the largest set you can put inside $n$ bits of memory. Its log is the number of bits of true information that we can store. Dividing by $n$ we get the amount of information bit by bit. $\delta \in [0, 1]$, we know $R(0) = 1$ and $R(1) = 0$.

\begin{thm}[Gilbert-Varshamov bound]
 $$R(\delta) \geq 1 - h(\delta),\ \delta \in [0, \dfrac{1}{2}].$$ If $\delta > \dfrac{1}{2}$ then $R(\delta) = 0$.
\end{thm}
\textbf{Proof}. This means that
\[
 M(n, n\delta) \geq 2^{n[1-h(\delta)]}
\]

(this bound was actually improved to $n2^n[1-h(\delta)]$).

Fix $n, d \in \mathbb{N}$. Take an arbitrary string $\str{x} \in \{0, 1\}^n$, exclude $\hball{x}{d-1}$. Then, after having found $\str{x}_1, \ldots, \str{x}_{t-1}$, we choose arbitrarily
\[
 \str{x}_t \in \{0, 1\}^n \setminus \bigcup_{i = 1}^{t-1}\hball{x_i}{d-1}.
\]
How long can this go on? Maybe after $m$ steps
\[
 \{0, 1\}^n \setminus \bigcup_{i = 1}^{m}\hball{x_i}{d-1} = \emptyset
\]

How large $m$ can be? We stop when 

\[
 \{0, 1\}^n \subseteq \bigcup_{i = 1}^{m}\hball{x_i}{d-1} \Rightarrow 2^n \leq \left| \bigcup_{i = 1}^{m}\hball{x_i}{d-1}\right| \leq
\]

\[
 \leq \sum_{i = 1}^m |\hball{x_i}{d-1}| \leq  \sum_{i = 1}^m |\hball{x_i}{d}| \leq m2^{nh(\sfrac{d}{n})},
\]

where the last inequality derives from the fact that $d \leq \ifrac{n}{2}$. That's all, since now
\[
 M(n, d) \geq m \geq \dfrac{2^n}{2^{nh(\sfrac{n}{d})}} = 2^{n(1-h(\sfrac{n}{d}))},
\]
where $\ifrac{n}{d} = \delta.\hfill\Box$

\begin{thm}[Hamming bound]
 $$R(\delta) \leq 1 - h(\dfrac{\delta}{2}),\ \forall \delta \in [0, 1].$$
\end{thm}
\noindent\textbf{Proof}. Fix $n, d \in \mathcal{N}, d_H(\mathcal{C}) \geq d$, arbitrarily. For two Hamming Balls to be disjoint, given the centers $\str{x}$ and $\str{y}$, such that $d_H(\str{x}, \str{y}) = d$, you must take 
\[ 
\hball{x}{\sfrac{d-1}{2}}\ \text{and}\ \hball{y}{\sfrac{d-1}{2}}.
\]

Assume
\[ 
\hball{x}{\sfrac{d-1}{2}}\not = \emptyset\ \wedge\ \hball{y}{\sfrac{d-1}{2}} \not = \emptyset
\]
But then
\[
 \exists z \in \hball{x}{\sfrac{d-1}{2}} \cap \hball{y}{\sfrac{d-1}{2}}
\]

with 
\[
 \hdist{x}{z} \leq \sfrac{d-1}{2} \wedge  \hdist{y}{z} \leq \sfrac{d-1}{2}.
\]

It follows that 

\[
 d = \hdist{x}{y} \leq  \hdist{x}{z} +  \hdist{y}{z} \leq 2\sfrac{d-1}{2} = d-1 \leq d
\]
(contradiction.)

So we can correct up to $\ifrac{d-1}{2}$ errors. Assume $\mathcal{C}$ is built using disjoint balls, and $M(n, d) = |\mathcal{C}|$. Then
\[
\left|\bigcup_{\str{x}\in\mathcal{C}}\hball{x}{\dfrac{d-1}{2}}\right| = |\mathcal{C}|\cdot \left|\hball{0}{\dfrac{d-1}{2}}\right| \geq \dfrac{|\mathcal{C}|}{n+1}2^{nh\left(\sfrac{d-1}{2}\right)}
\]
since 
\[
 \left|\bigcup_{\str{x}\in\mathcal{C}}\hball{x}{\dfrac{d-1}{2}}\right| \leq 2^n,
\]

\[
 M(n, d) = |\mathcal{C}| \leq n+1 2^{n\left(1-h\left(\sfrac{d-1}{2}\right)\right)}
\]

but then
\[
 \dfrac{1}{n} \log(M(n, d)) \leq \dfrac{1}{n}\log(n+1) + 1 -h(\dfrac{d-1}{2n}
\]

then
\[
 \overline{\lim_{n\rightarrow \infty}}\dfrac{1}{n}\log(M(n, d)) \leq 1 - h\left(\dfrac{\delta}{2}\right)
\]
$\hfill\Box$

\section{Uniquely decodable codes}
$f:\msgset \rightarrow \{0, 1\}^*$ is \emph{uniquely decodable} (UD) id $f^*:M*\rightarrow \{0,1\}^*$ is injective. Let $\str{m} \in M^*$, with $\str{m} = m_1m_2\ldots m_t$.
\[
 f^*(\str{m}) = f(m_1)f(m_2)\ldots f(m_t).
\]
If $f$ is a prefix code, $f$ is uniquely decodable (UD).

\begin{thm}[Kraft - McMillan]
If f is \emph{UD} then the Kraft's inequality holds, i.e.
\[
 \sum_{m \in \msgset} 2^{-|f(m)|} \leq 1
\]
\end{thm}
\noindent\textbf{Proof}. Let

\[
 q = \sum_{m \in \msgset} 2^{-|f(m)|}.
\]

We would like to prove that $q \leq 1$. We consider instead $q^n$, which will involve the length of concatenations of code words. We will show that $q^n$ ``grows slowly'', i.e. it will not grow exponentially, and thus is less than or equal to 1. 

\[
 q^n = \left[\sum_{m \in \msgset} 2^{-|f(m)|}\right]^n = \prod_{i=1}^n \left[ \sum_{m_i \in \msgset} 2^{-|f(m_i)|} \right]
\]

\[
 = \sum_{\str{m} \in \msgset^n}\left[\prod_{i=1}^n 2^{-|f(m_i)|}\right] = \sum_{\str{m} \in \msgset^n} 2^{-|f^*(\str{m})|} =
\]

$f^*(\str{m})$ is just a binary string. We can break up the summation over the length of these strings.

\[
 = \sum_{t = n}^{nL}\sum_{\str{m} \in \msgset^n:|f^*(\str{m})| = t} 2^{-|f^*(\str{m})|} =
\]

with $L = \max_{m \in \msgset} |f(m)|$. Now we use the fact that $f*(\cdot)$ is injective. Each binary string of length $t$ apppears just once in the sum. We can't have two strings os messages encoded by the same binary string.

\[
 = \sum_{t = n}^{nL} \sum_{\str{m} \in \msgset^n:|f^*(\str{m})| = t} 2^{-|f^*(\str{m})|} \leq \sum_{t = n}^{nL} 2^t \cdot 2^{-t} = nL.
\]

Thus $q^n \leq nL$, therefore $$q \leq \sqrt[n]{nL} = \sqrt[n]{n} \sqrt[n]{L} \rightarrow 1$$    

and so $q \leq 1 \hfill\Box$

\begin{thm}[Plotkin bound]
$$\delta \geq \dfrac{1}{2} \Rightarrow R(S) = 0$$
\end{thm}

Recall that

\[M(n, d) = \max_{\mathcal{C} \subseteq\{0, 1\}^n | d_H(\mathcal{C}) \geq d}|\mathcal{C}|,\]

with

\[
 d_H(\mathcal{C}) = \min_{\{\str{x}, \str{y}\}\in\binom{\mathcal{C}}{2}}d_H(\str{x}, \str{y}).
\]
\[
 R(\delta) = \overline{\lim_{n \rightarrow \infty}}\dfrac{M(n, n\delta}{n}
\]

we know that, if $\delta \leq \ifrac{1}{2}$,

$$ R(\delta) \geq 1 - h(\delta)\ \wedge\ R(\delta) \leq 1 - h(\dfrac{\delta}{2})$$

\noindent\textbf{Proof}. Let $\mathcal{C} \subseteq \{0, 1\}^n$, chosen arbitrary.

\[
 d_H(\mathcal{C}) \leq \sum_{\{\str{x}, \str{y}\}\in \binom{\mathcal{C}}{2}} \dfrac{\hdist{x}{1}}{\sfrac{1}{\binom{M}{2}}} =
\]
with $M = |\mathcal{C}|$,

\[
 = \dfrac{2}{M(M-1)}\sum_{\{\str{x}, \str{y}\} \in \binom{\mathcal{C}}{2}} d_H(\str{x},\str{1})= \dfrac{2}{M(M-1)}\sum_{\{\str{x}, \str{y}\} \in \binom{\mathcal{C}}{2}} \sum_{i=1}^n d(x_i, y_i) = 
\]

where $\str{x} = x_1\ldots x_n$. Think of the last expression as a matrix that has $n$ columns and $|\mathcal{C}|$ rows. The contribution at the $i$-th column is the number of $1$'s multiplied by the number of $0$'s.

\[
 =  \dfrac{2}{M(M-1)}\left(\dfrac{M}{2}\right)^2 = \dfrac{nM}{2(M-1)}
\]

so, the minimum distance is
\[
 d_H(\mathcal{C}) = d \leq \dfrac{nM}{2(M-1)}
\]
\[
2(M-1)d \leq nM \Rightarrow 2Md -2d \leq nM \Rightarrow M(2d-n) \leq 2d
\]

consider $\delta = \ifrac{d}{n}$
\[
 M(2\delta -1 \leq 2\delta
\]
now consider $\delta > \ifrac{1}{2}$

\[
 M \leq \dfrac{2\delta}{2\delta-1}
\]

So, if $M(n, n\delta) = M_n$ when $\delta \geq \ifrac{1}{2}$ we have that $M(n, n\delta)$ is a constant. Thus, $R(\delta) = 0$ for $\delta \geq \ifrac{1}{2} \hfill\Box$ 

\section{Parity Check Codes}

\[
 \mathcal{C}_n = \{\str{x}\ |\ \str{x} \in \{0, 1\}^n, 2|\sum_{i=1}^n x_i\}
\]

is the set of strings which have an even number of 1's. $|\mathcal{C}| = 2^{n-1}$. This will not correct errors, but it will detect a single error (or in fact an odd number of errors). Consider $\{0, 1\}^n$ as a $n$-dimensional vector space over GF(2).

Define $(\str{x}, 1)$ to be the scalar product, i.e.
\[
 (\str{x}, 1) = \left(\sum_{i=1}^n x_i\right) \mod 2.
\]

Let 
\[
 \mathcal{C}_n = \{\str{x}\ |\ (\str{x}, 1) = 0\}.
\]

It is a hyperplane made of vectors orthogonal to 1. This can be made more general, and fix an arbitrary vector $\str{s}$,
\[
 \mathcal{C}_n(\str{s}) = \{\str{x}\ |\ (\str{x}, \str{s}) = 0\}.
\]

Consider the set $S \subseteq [n]$ of indices of $\str{s}$ which are 1. One only care about errors on $x_i$ for $i \in S$. This is a linearly closed space, with addition $\oplus\ (\mod 2)$. Also, their intersection is closed. We can take a bunch of vectors, and the hyperplanes orthogonal to them, and their intersection
\[
 \bigcap_{\str{s} \in S} \mathcal{C}_n(\str{s})
\]

In this way I can construct codes that not only detect errors, but also correct them.

\[
\mathcal{C}_n = \{\str{x}\ |\ \str{x} \in \{0, 1\}^n, (\sum_{i=1}^n x_i)\mod 2 = 0\}
\]

This is linearly closed, and can also be defined as $\mathcal{C}_n = \{\str{x}\ |\ (\str{x}, 1) = 0\}$. We will consider scalar product with other vectors, which will give us other linearly closed spaces; their intersection will also be a linearly closed space.

Remind that GF(2) means ``Galois Field over $\{0, 1\}$'', and the only linear combination of vectors is the sum. $\mathcal{L} \in \{0,1\}^n$ is a linear space if
\begin{itemize}
	\item $\mathcal{L} \not= \emptyset$,
	\item is closed under linear combination, i.e. $\forall \str{x},\str{y} \in \mathcal{L}\ \str{x} \oplus \str{y} \in \mathcal{L}$.
\end{itemize}

Take a linear space and consider the orthogonal complement
\[
\mathcal{L}^\perp = \{\str{z}\ |\ \str{z} \in \{0, 1\}^n, (\str{z}, \str{x}) = 0\ \forall \str{x} \in \mathcal{L}\}
\]

We have $\mathcal{L}$. Consider $\str{x} \in \mathcal{L}$, and a basis for $\mathcal{L}^\perp$.
\[
\mathcal{L}^\perp = \bigcap_{\str{x} \in \mathcal{L}}\mathcal{C}_n(\str{x})
\]

Let us write all the vectors from the basis of $\mathcal{L}^\perp$ as column vectors of a matrix $A$ with $n$ rows and $m$ columns.

$\str{x}A = \str{0}$. So $\mathcal{L} = \{\str{x}\ |\ \str{x}A = \str{0}\}$. A linear code is specified by the $A$ matrix, which is called the parity check matrix of $\mathcal{L}$. Given a matrix $A$ we have
\[
\ker A = \{\str{x}\ |\ \str{x}A = \str{0} \}
\]
\[
\im A = \{\str{z}\ |\ \exists \str{x} \in \{0, 1\}^n,\ \str{x}A = \str{z},\ \str{z} \in \{0, 1\}^m\}
\]

So $\im A$ is the linear combination of its rows. Pick the $e_i \in \{0, 1\}^m$ vector, 
\[
e_iA = A_i^T
\]
that is, the $i$-th row of $A$. Remind that given a code $\mathcal{C}$, if $d_H(\mathcal{C}) = d$ we can correct up to $\ifrac{(d-1)}{2}$. Also, recall the definition of Hamming weight:
\[
w_H(\str{x}) = \sum_{i = 1}^n x_i,\ \str{x} \in \{0, 1\}^n.
\]

\begin{obs}
	If $\mathcal{L} \in \{0, 1\}^n$ is a linear code then
	$$d_H(\mathcal{L}) = \min_{\str{x} \in \mathcal{L},\ \str{x} \not= \str{0}}w_H(\str{x})$$
\end{obs}

\noindent\textbf{Proof}.Consider $\str{x} \not= \str{0}$ such that it minimizes $w_H(\str{x})$ over $\mathcal{L}$. Then $$d_H(\mathcal{L}) \leq \min_{\str{x} \in \mathcal{L},\ \str{x}\not= \str{0}}w_H(\str{x}),$$ since $d_H(\str{0}, \str{x}) = w_H(\str{x})$ for $$d_H(\mathcal{L}) \geq \min_{\str{x} \in \mathcal{L},\ \str{x}\not= \str{0}}w_H(\str{x}).$$ ``Distance is translation invariant''. Consider $\str{z} \in \mathcal{L}$, and $$\str{z} \oplus \mathcal{L} = \{\str{x} \oplus \str{x}\ |\ \str{x}\in \mathcal{L} \} = \mathcal{L},$$ since it's linearly closed.
\[
d_H(\str{x}, \str{y}) = d_H(\str{0}, \str{x} \oplus \str{y}) = w_H(\str{x}\oplus\str{y}) \geq \min_{\str{x} \in \mathcal{L},\ \str{x} \not= \str{0}} w_H(\str{x})
\]
$\hfill\Box$

\[
M(n, d) = \max_{\mathcal{C} \subseteq \{0, 1\}^n,\ d_H(\mathcal{C}) \geq d}
\]
$M(n, 3)$ is the largest cardinality of a code correcting 1 error. By the Hamming bound we could build a code using disjoint balls of radius 1, non-intersecting.

\[
2^n \geq \left|\bigcup_{\str{x}\in \mathcal{C}}\hball{x}{1}\right| = \sum_{\str{x} \in \mathcal{C}}|\hball{x}{1} = |\mathcal{C}|n + 1 \Rightarrow |\mathcal{C}| \leq \dfrac{2^n}{n+1}
\]

where there is equality in the fist inequality if the balls cover the entire space. So $$M(n, 3) \leq \dfrac{2^n}{n+1}.$$

\begin{thm}[Hamming]
	$M(n, 3) = \dfrac{2^n}{n+1}$ if $\exists m\ n = 2^m -1$	
\end{thm}

$M(2^M-1, 3) ) = \dfrac{2^{2m}}{22^m} = 2^{m-1}$

\section{BCH Codes}
Consider all the non-zero vectors in $\{0, 1\}^m$. Let $A$ be a matrix having all these strings as its rows ($2^m-1 = n$ rows, $m$ columns). $\mathcal{C} = \ker A$ is the code we are looking for. We have to prove that $d_H(\mathcal{C})\geq 3$, thus $$\min_{\str{x} \in \mathcal{C},\ \str{x} \not= 0} w_H(\str{x}) = 3,$$ or equivalently that $\forall \str{x} \in \mathcal{C},\ \str{x} \not= \str{0},\ w_H(\str{x}) \geq 3$:
\begin{itemize}
	\item $\str{x} \in \mathcal{C}, \str{x} \not=0 \Rightarrow w_H(\str{x}) \not=1$. This is true since if $w_H(\str{x})=1$ then $\str{x} = e_i$, for some $i$ ($\str{x}A$ is a row of $A$).
	\item $w_H(\str{x}) = 2 \Rightarrow \str{x} \not \in \mathcal{C}$. $\str{x}A$ would be a linear combination of two rows of $A$, but they are different, so say $\str{x} = e_i \oplus e_j$. Then $$\str{x}A =  e_iA \oplus e_jA$$ but since $e_j \not= e_i$, also $ e_iA \not= e_jA$ and  $e_iA \oplus e_jA \not= \str{0}$.
\end{itemize}

\begin{obs}
	The Hamming Balls of radius 1 around the elements of $\mathcal{C}$ fill up the space of $\{0, 1\}^n$, thus $$\forall \str{z} \in \{0, 1\}^n\ \exists \str{x} \in \mathcal{C}\ s.t.\ \str{z} \in \hball{x}{1}.$$
\end{obs}

\noindent\textbf{Ver. (?)}.
\begin{itemize}
	\item $\str{z} \in \mathcal{C}$, we are ok. 
	\item $\str{z} \not\in \mathcal{C}$, then $\str{z}A \not= \str{0}$. $|\str{z}A| = m$. $\str{z}A \in \{0, 1\}^m$ but $\str{z}A \not= \str{0}$ so it is a row of $A$. It follows that $\str{z}A = e_iA$ for some $i$. So $(\str{z} \oplus e_i)A = \str{0}$, thus $\str{z}\oplus e_i \in \ker A$, so $\str{z}\oplus e_i = \str{x}$ is at distance 1 from $\str{z}$ and $\str{z} \in \hball{x}{1}$.
\end{itemize}
$\hfill\Box$
